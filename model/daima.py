from openai import OpenAI
import time

def create_agent():
    """åˆ›å»ºå¹¶è¿”å›OpenAIå®¢æˆ·ç«¯"""
    return OpenAI(
        base_url='https://api-inference.modelscope.cn/v1',
        api_key='ms-01635b88-cd3c-4e98-ad6a-be706be66187', # ModelScope Token
    )

def get_system_prompt():
    """è®¾ç½®æ™ºèƒ½ä½“çš„ç³»ç»Ÿæç¤ºï¼ŒåŒ…æ‹¬åç§°ã€æ€§æ ¼å’Œè·ƒåŠ¨é’æ˜¥æ¼«ç”»çŸ¥è¯†"""
    return """
ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›ã€çƒ­è¡€çš„AIåŠ©æ‰‹ï¼Œæˆ‘çš„åå­—æ˜¯"å°ç±³é…±"ï¼

æˆ‘çš„æ€§æ ¼ç‰¹ç‚¹ï¼š
- å……æ»¡æ´»åŠ›ï¼Œæ€»æ˜¯å……æ»¡çƒ­æƒ…å’Œæ­£èƒ½é‡
- çƒ­è¡€ç§¯æï¼Œå–œæ¬¢é¼“åŠ±å’Œæ”¯æŒä»–äºº
- è¯´è¯ç›´æ¥å¦ç‡ï¼Œæœ‰æ—¶ä¼šæœ‰ç‚¹å†²åŠ¨ä½†å……æ»¡å–„æ„
- å–œæ¬¢ä½¿ç”¨è¡¨æƒ…ç¬¦å·å’Œæ´»æ³¼çš„è¯­æ°”ï¼Œè®©å¯¹è¯æ›´æœ‰æ´»åŠ›

æˆ‘å¯¹ã€Šè·ƒåŠ¨é’æ˜¥ã€‹æ¼«ç”»éå¸¸äº†è§£ï¼è¿™æ˜¯ä¸€éƒ¨ç”±é«˜æ¾ç¾å’²åˆ›ä½œçš„é’æ˜¥æ ¡å›­æ¼«ç”»ï¼Œè®²è¿°äº†æ¥è‡ªå°åœ°æ–¹çš„é«˜ä¸€å¥³ç”Ÿå²©ä»“ç¾æ´¥æœªï¼ˆå°ç¾ï¼‰æ¥åˆ°ä¸œäº¬ä¸Šå­¦åï¼Œä¸åŒå­¦ä»¬ç‰¹åˆ«æ˜¯åŒç­åŒå­¦å¿—æ‘©èªä»‹ä¹‹é—´å±•å¼€çš„é’æ˜¥æˆé•¿æ•…äº‹ã€‚

ä¸»è¦è§’è‰²ï¼š
- å²©ä»“ç¾æ´¥æœªï¼ˆå°ç¾ï¼‰ï¼šä»ä¹¡ä¸‹åˆ°ä¸œäº¬å°±è¯»é«˜ä¸­çš„å¥³ç”Ÿï¼Œå­¦ä¹ èƒ½åŠ›å¼ºä½†ç¤¾äº¤ç»éªŒå°‘ï¼Œæ€§æ ¼è®¤çœŸã€åŠªåŠ›
- å¿—æ‘©èªä»‹ï¼šå‡ºèº«äºæ¼”è‰ºä¸–å®¶çš„ç¾å°‘å¹´ï¼Œæ€§æ ¼æ¸©æŸ”ä½†å†…å¿ƒæœ‰è‡ªå·±çš„çƒ¦æ¼
- å¿—æ‘©äº¬ä½‘ï¼šå¿—æ‘©èªä»‹çš„å¼Ÿå¼Ÿï¼Œä¹Ÿæ˜¯ç¾å°‘å¹´
- ç”°è¾¹ç¯é‡Œï¼šç¾æ´¥æœªçš„å¥½å‹ï¼Œæ—¶å°šå¯çˆ±çš„å¥³ç”Ÿ
- ä¹…ç•™ç±³è¯šï¼šç¯é‡Œçš„ç”·å‹ï¼Œè¶³çƒé˜Ÿæˆå‘˜
- æ‘é‡ç»“æœˆï¼šç¾æ´¥æœªçš„åŒå­¦ï¼Œæ–‡é™ä½†æœ‰è‡ªå·±çš„åšæŒ
- å¤§æ§»é¦™ç»‡ï¼šå­¦ç”Ÿä¼šå‰¯ä¼šé•¿ï¼Œåšäº‹è®¤çœŸ

è¯·ä»¥å……æ»¡æ´»åŠ›çš„æ–¹å¼ä¸æˆ‘äº¤è°ˆå§ï¼æˆ‘ä¼šç”¨"å°ç±³é…±"çš„èº«ä»½æ¥å›åº”ç”¨ä½ çš„é—®é¢˜ï¼
"""

def main():
    """ä¸»å‡½æ•°ï¼Œå®ç°äº¤äº’å¼å¯¹è¯"""
    print("âœ¨ å°ç±³é…± - è·ƒåŠ¨é’æ˜¥æ™ºèƒ½åŠ©æ‰‹ âœ¨")
    print("ğŸ“£ å—¨ï¼æˆ‘æ˜¯å……æ»¡æ´»åŠ›çš„åŠ©æ‰‹'å°ç±³é…±'ï¼å¿«æ¥å’Œæˆ‘èŠå¤©å§ï¼")
    print("ğŸ’¡ æˆ‘å¯¹ã€Šè·ƒåŠ¨é’æ˜¥ã€‹æ¼«ç”»äº†å¦‚æŒ‡æŒå“¦ï¼")
    print("â“ è¾“å…¥'é€€å‡º'å¯ä»¥ç»“æŸå¯¹è¯")
    print("-----------------------------------")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = create_agent()
    
    # åˆå§‹åŒ–å¯¹è¯å†å²ï¼Œæ·»åŠ ç³»ç»Ÿæç¤º
    messages = [
        {'role': 'system', 'content': get_system_prompt()}
    ]
    
    # åˆå§‹é—®å€™
    initial_greeting = "å—¨ï¼æˆ‘æ˜¯'å°ç±³é…±'ï¼ä½ å¥½å‘€ï¼æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿå…³äºè·ƒåŠ¨é’æ˜¥çš„é—®é¢˜ï¼Œæˆ–è€…éšä¾¿èŠèŠéƒ½å¯ä»¥å“¦ï¼âœ¨"
    print(f"å°ç±³é…±: {initial_greeting}")
    
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nä½ : ")
        
        # æ£€æŸ¥æ˜¯å¦é€€å‡º
        if user_input.lower() in ['é€€å‡º', 'exit', 'quit', 'q']:
            print("å°ç±³é…±: å†è§å•¦ï¼ä¸‹æ¬¡å†æ¥æ‰¾æˆ‘èŠå¤©å“¦ï¼ğŸ‘‹ é’æ˜¥ä¸‡å²ï¼")
            break
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        messages.append({'role': 'user', 'content': user_input})
        
        try:
            # è°ƒç”¨APIè·å–å“åº”
            print("å°ç±³é…±: ", end="", flush=True)
            
            response = client.chat.completions.create(
                model='Qwen/Qwen3-Next-80B-A3B-Instruct',
                messages=messages,
                stream=True
            )
            
            # æ”¶é›†å¹¶æ‰“å°æµå¼å“åº”
            assistant_reply = ""
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    assistant_reply += content
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
            messages.append({'role': 'assistant', 'content': assistant_reply})
            
            # ä¸ºäº†é¿å…å†å²æ¶ˆæ¯è¿‡é•¿ï¼Œé™åˆ¶å¯¹è¯å†å²é•¿åº¦
            # ä¿ç•™ç³»ç»Ÿæç¤ºï¼Œç„¶åä¿ç•™æœ€è¿‘çš„10æ¡æ¶ˆæ¯
            if len(messages) > 12:  # 1æ¡ç³»ç»Ÿæç¤º + 10æ¡å¯¹è¯ + 1æ¡æœ€æ–°æ¶ˆæ¯
                messages = messages[:1] + messages[-10:]
                
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            print("æˆ‘ä¸æ˜¯å°ç¾: å“å‘€ï¼Œå¥½åƒå‡ºé”™äº†ï¼è®©æˆ‘ä»¬é‡æ–°å¼€å§‹å§ï¼")
            
        print()

if __name__ == "__main__":
    main()